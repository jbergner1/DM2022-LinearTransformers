{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LinearAttention{Q<:Dense, K<:Dense, V<:Dense, O<:Dense, DP<:Dropout} <: AbstractAttention\n",
    "    head::Int\n",
    "    future::Bool\n",
    "    iqproj::Q\n",
    "    ikproj::K\n",
    "    ivproj::V\n",
    "    oproj::O\n",
    "    drop::DP\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.functor(mh::LinearAttention) = (mh.iqproj, mh.ikproj, mh.ivproj, mh.oproj), m -> LinearAttention(mh.head, mh.future, m..., mh.drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearAttention_1(head::Int,\n",
    "                   is::Int,\n",
    "                   hs::Int,\n",
    "                   os::Int;\n",
    "                   future::Bool=true, pdrop = 0.1) = LinearAttention(head,\n",
    "                                                                        future,\n",
    "                                                                        Dense(is, hs*head),\n",
    "                                                                        Dense(is, hs*head),\n",
    "                                                                        Dense(is, hs*head),\n",
    "                                                                        Dense(hs*head, os),\n",
    "                                                                        Dropout(pdrop),\n",
    "                                                                        )\n",
    "\n",
    "\n",
    "function Base.show(io::IO, mh::LinearAttention)\n",
    "    hs = div(size(mh.iqproj.weight)[1], mh.head)\n",
    "    is = size(mh.iqproj.weight)[end]\n",
    "    os = size(mh.oproj.weight)[1]\n",
    "\n",
    "    print(io, \"LinearAttention(\")\n",
    "    print(io, \"head=$(mh.head), \")\n",
    "    print(io, \"head_size=$(hs), \")\n",
    "    print(io, \"$(is)=>$(os)\")\n",
    "\n",
    "    if Flux.istraining()\n",
    "        print(io, \", dropout=$(mh.drop.p))\")\n",
    "    else\n",
    "        print(io, \")\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (mh::LinearAttention)(query::A1,\n",
    "    key::A2,\n",
    "    value::A3;\n",
    "    mask=nothing) where {T,\n",
    "                         A1 <: Abstract3DTensor{T},\n",
    "                         A2 <: Abstract3DTensor{T},\n",
    "                         A3 <: Abstract3DTensor{T}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# of type float (to allow for integer inputs)\n",
    "oftf(x, y) = oftype(float(x), y)\n",
    "nelu(x, α=1) = ifelse(x ≥ 0, float(x)+1, @fastmath oftf(x, α) * (exp(x) - 1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function splitHeads(x, batch, head, depth)\n",
    "    x = reshape(x, (batch, -1, head, depth))\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @toNd not defined\nin expression starting at Untitled-1.ipynb:13",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @toNd not defined\n",
      "in expression starting at Untitled-1.ipynb:13\n",
      "\n",
      "Stacktrace:\n",
      "  [1] top-level scope\n",
      "    @ :0\n",
      "  [2] eval\n",
      "    @ ./boot.jl:360 [inlined]\n",
      "  [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:1116\n",
      "  [4] #invokelatest#2\n",
      "    @ ./essentials.jl:708 [inlined]\n",
      "  [5] invokelatest\n",
      "    @ ./essentials.jl:706 [inlined]\n",
      "  [6] (::VSCodeServer.var\"#146#147\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.11/scripts/packages/VSCodeServer/src/serve_notebook.jl:18\n",
      "  [7] withpath(f::VSCodeServer.var\"#146#147\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.11/scripts/packages/VSCodeServer/src/repl.jl:185\n",
      "  [8] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.11/scripts/packages/VSCodeServer/src/serve_notebook.jl:14\n",
      "  [9] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.5.11/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [10] serve_notebook(pipename::String; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.11/scripts/packages/VSCodeServer/src/serve_notebook.jl:94\n",
      " [11] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.5.11/scripts/notebook/notebook.jl:12\n",
      " [12] include(mod::Module, _path::String)\n",
      "    @ Base ./Base.jl:386\n",
      " [13] exec_options(opts::Base.JLOptions)\n",
      "    @ Base ./client.jl:285\n",
      " [14] _start()\n",
      "    @ Base ./client.jl:485"
     ]
    }
   ],
   "source": [
    "function (mh::LinearAttention)(query::A1,\n",
    "    key::A2,\n",
    "    value::A3;\n",
    "    mask=nothing) where {T,\n",
    "                         A1 <: Abstract3DTensor{T},\n",
    "                         A2 <: Abstract3DTensor{T},\n",
    "                         A3 <: Abstract3DTensor{T}}\n",
    "qs = size(query)\n",
    "ks = size(key)\n",
    "vs = size(value)\n",
    "\n",
    "#size(ipq) == (h, q_seq_len, batch)\n",
    "ipq = @toNd mh.iqproj(query)\n",
    "ipk = @toNd mh.ikproj(key)\n",
    "ipv = @toNd mh.ivproj(value)\n",
    "\n",
    "h = size(ipq, 1)\n",
    "hs = div(h, mh.head)\n",
    "\n",
    "ipq = nelu(splitHeads(ipq, qs[1], mh.head, hs))\n",
    "ipk = nelu(splitHeads(ipk, qs[1], mh.head, hs))\n",
    "ipv = nelu(splitHeads(ipv, qs[1], mh.head, hs))\n",
    "\n",
    "@einsum kv[m,d,e,h] = ipk[m,j,h,d]*ipv[m,j,h,e]\n",
    "\n",
    "sum_1 = sum(ipk, axis=1) + 1e-8\n",
    "\n",
    "@einsum z_1[m,l,h] = ipq[m,l,h,d]*sum_1[m,h,d]\n",
    "\n",
    "z = 1/z_1\n",
    "\n",
    "@einsum output[m,l,h,e] = ipq[m,l,h,d]*kv[m,d,e,h]*z[m,l,h]\n",
    "\n",
    "output = reshape(output, (qs[1], -1, mh.head*hs))\n",
    "\n",
    "return output\n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
