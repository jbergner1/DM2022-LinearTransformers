\documentclass[DIV=13,fontsize=11pt]{scrartcl}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}


\title{Replication of "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}
%\head{Titel ersetzen und Sub-Titel streichen.}
\author{Viet-Anh Do and Johannes Bergner}
\date{Version 1.0.2, 14.2.2022}

\begin{document}
\maketitle
\section{Introduction}
%Beschreiben sie mit ein paar Sätzen den Kontext der replizierten/reproduzierten Arbeit. Es werden höchstens drei bis vier Paragraphen erwartet. Sie sollen hinreichend erklären, was das das Problem ist, das der Artikel bearbeitet, warum es ein wichtiges Problem ist und das die Beiträge des replizierten/reproduzierten Artikel ist. Zitieren sie in diesem Abschnitt relevante wissenschaftliche Arbeiten. 

Transformers introduced by (Vaswani et al., 2017) are the state-of-the-art in  tasks like language understanding and image processing.  However their quadratic memory complexity within the self-attention mechanism weakens the efficiency when dealing with long sequences.  
Consequently a number of so called \("X\)-\(former"\)- models have been proposed, that improve the original Transformer in terms of computational and memory efficiency.

Next to other approaches, like Performer (Choromanski et al., 2020), Linformer (Wang et al., 2020) and Big Bird (Zaheer et al., 2020) the authors of "Transformers are RNNs" developed a Linear Transformer (Katharopoulus et al., 2020) to show how the quadratic complexity \(O(N^2)\)  can be reduced to a linear complexity of \(O(N)\) without reducing the accuracy.

Standard Transformers use the folllowing attention matrix:

\begin{align}
    Attention(Q, K, V) {=} V {=} softmax \left(\frac {QK^T}{\sqrt{D_{k}}}\right) V,
\end{align}

with the queries Q \( \in \mathbb{R}^{N \times D_{k}}\),  keys K \(\in \mathbb{R}^{M \times D_{k}}\) and values V \( \in \mathbb{R}^{N \times D_{v}}\), where N and M represent the lenghts of queries and keys (or values) and \(D_{k}\) and \(D_{v}\) the dimensions of the keys (or queries) and values. The softmax function is applied rowwise to \(QK^T\).

(Katharopoulus et al., 2020) simplify this attention mechanism by generalizing equation (1) and replacing the softmax with the kernel feature map \(\phi (x) {=} elu(x) +1\):

\begin{align}
    V_{i}' {=} \frac{\phi(Q_{i})^T \sum_{j=1}^{i} \phi(K_{j})V_{j}^T}{\phi(Q_{i})^T \sum_{j=1}^{i}\phi(K_{j})}
\end{align}

Because of that \(\sum_{j=1}^{i} \phi(K_{j})V_{j}^T\) and \(\sum_{j=1}^{i}\phi(K_{j})\) can be computed once and reused for every query, which leads to a time and memory complexity of \(O(N)\). Furthermore by representing these cumulated sums as \(S_{i}\) and \(Z_{i}\), they can be seen as states of an RNN for causal attention and computed from \(S_{i-1}\) and \(Z_{i-1}\) in constant time.

In tests the Linear Transformer of (Katharopoulus et al., 2020) performed an image generation task based on the CIFAR-10 dataset over 4,000 times faster than the normal transformer with the same accuracy.  These results seem extraordinary, which is why the Linear Transformer has been recognized in further scientific research and the paper \("Transformers\) \( are\) \(RNNs"\) has been recited about 250 times in nearly two years. 

Nevertheless papers that benchmark the improvements in the Transformer architecture, like (Yi et al., 2020) show, that Linear Transformer perform faster then the original Transformer but not as high as 4,000 times faster. In this replication we will try to replicate a Linear Transformer in Julia in order to examnie if five-digit speed improvements are really possible.






% Was ist der Beitrag des replizierten Artikels?
% Welche Teile der Arbeit wurden für die Replikation ausgewählt? Begründen Sie die Auswahl. Warum wurden andere Teile der Arbeit nicht repliziert?
% Welche neuen Erkenntnisse erwarten Sie durch die geplante Reproduktion? Was steht davon nicht in dem replizierten Artikel?
% Was ist der Beitrag bzw. sind die Beiträge Ihres Artikels über die Reproduktion der ausgewählten Arbeit?

\section{Scope of the replication}
%Erklären sie die Behauptungen/Hypothesen/Experimente des Artikels, die sie für ihre Replikation/Reproduktion ausgewählt haben.
%Motivieren und begründen sie ihre Auswahl. 
%Es ist sinnvoll, wenn sie sich auf die Behauptung konzentrieren, die der Hauptbeitrag des Artikels ist.
%Um den Hauptbeitrag herauszufinden, versuchen sie den Artikel in ein bis zwei Sätzen zusammenzufassen, z.B.
%\begin{quote}
   % ``This paper introduces a new activation function X that outperforms a similar activation %function Y on tasks Z,V,W.''  oder 
    
   % ``Dieser Artikel führt eine neuartige Aktivierungsfunktion X ein, welche die ähnliche Aktivierungsfunktionen Y für die Aufgaben Z,W,V deutlich verbessert.''
%\end{quote}
%Stecken sie den Umfang ihrer Replikation/Reproduktion so klar wie möglich ab. 
%Die Behauptungen ihres Berichts sollten durch die Ergebnisse ihrer Experimente unterstützt oder widerlegt werden.
%Schauen sie sich zum Beispiel diese Beschreibung an:
%\begin{quote}
   % ``Contextual embedding models have shown strong performance on a number of tasks across NLP. We will run experiments evaluating two types of contextual embedding models on datasets X, Y, and Z.'' oder 
    
   % ``Für Contextual-Embedding-Modelle wurde nachgewiesen, dass die bei einer Vielzahl von Aufgaben aus einem breiten Spektrum natürlichen Sprachverarbeitung (NLP) eine hervorragende Leistung erbringen. Wir evaluieren experimentell zwei verschiedene Arten von Contextual-Embedding-Modellen auf den Datensätzen X, Y, Z.''    
%\end{quote}
%Der Umfang ist zu breit angelegt und es fehlt die Erwartung für ein klares Ergebnis.
%Schauen sie sich die nächste Beschreibung an:
%\begin{quote}
%``Finetuning pretrained BERT on SST-2 will have higher accuracy than an LSTM trained with GloVe embeddings.'' oder

%``Das Anpassen eines vortrainierten BERT-Modells für die SST-2-Aufgabe führt zu einer höheren Klassifikationsrate als ein LSTM-Modell, das für GloVe-Einbettungen trainiert wurde''
%\end{quote}
%Hier ist klarer was bei der Reproduktion/Replikation herauskommen kann. Diese Aussage könnte durch ihre Ergebnisse tatsächlich bestätigt oder widerlegt werden. 

Due to their linear complexity, Linear Transformers are said to be highly efficient when the sequence length increases. (Katharopoulus et al., 2020) evaluate their Transformer on image generation and automatic speech recognition and conclude, that their Linear Transformer is up to three orders of magnitude faster than regular Transformers while reaching the same performance levels.  In this Replication we want to investigate, if Linear Transformers perform tasks with long sequences as precise as the original Transformer, but significantly faster. 

However, the official GitHub Repository of the paper does not contain experiments. The authors published their experiments in a seperate GitHub Repository, that contains evaluations on image generation and a copy task of number sequences.  In order to examine speed and precision with growing sequence length, a copy task of number sequences is favourable because it is easy to increase the sequence length and to evaluate the results. Furthermore an example of a copy task is already given in the Julia package Transformers.jl. We will use this example as a benchmark, that represents the performance of the Transformer by (Vaswani et al., 2017). Based on that we are going to replace the softmax-based attention function by a linear attention function. Then we apply different sequence lengths and examine, if the Linear Transformer performs faster but with the same precision as the original Transformer especially with high sequence lenghts. 

%Führen sie eindeutig die Behauptungen auf, die sie in ihrer Arbeit untersuchen. 
%\begin{itemize}
   % \item Behauptung 1
   % \item Behauptung 2
   % \item Behauptung 3
%\end{itemize}

\section{Methoden}

%In this section you explain your approach -- did you use the author's code, did you aim to re-implement the approach from the paper description? Summarize the resources (code, documentation, GPUs) that you used. 

\subsection{Modellbeschreibung}
For this replication a minimalistic model was developed to determine the convergence properties of Linear Transformers. The Transformer which was introduced by Vaswani et al. (2017) has been chosen as our baseline in this experiment. Unlike this aforementioned model which utilized softmax attention, the authors shifted the feature map into the module attention, computed the dot product of key and value instead of key and query so that the attention matrix never be explicitly computed and thus decrease the complexity from \(O(N^2 max(D,M))\) to \(O(ND^2M)\), where \(N >\) \(D^2\) in practice. Our target is to determine, whether Linear Attention converges faster than the softmax attention for given sequence length.  
%Beischreiben sie die Modelle, die im Originalartikel genutzt werden, einschließlich der Architektur, der Zielfunktion und der Parameter. 
%Describe the models used in the original paper, including the architecture, learning objective and the number of parameters.

\subsection{Datenbeschreibung}
For this synthetic task, we use a sequence of maximum length 128 with 10 different symbols separated by a dedicated separator symbol. These sequences are randomly generated.
%Beschreiben sie die Datenmengen die sie genutzt haben und wie sie sie bekommen haben. 
%Describe the datasets you used and how you obtained them. 

\subsection{Hyperparameter}
We have adjusted the hyperparameters of the model according to the original paper. The number of head per Transformer is 8, whose size is 64, which leads to the size of the whole Transformer of 512. The original length is kept the same as in the original paper at 128 whereas the learning rate will stay constantly at \(10^-3\). 
%Beschreiben sie, wie sie Hyperparameter gesetzt haben. Welche Quellen haben sie für die konkreten Werte genutzt (z.B. den Forschungsartikel, Code oder sie hatten eine wohlbegründete Vermutung, educated guess).
%Describe how you set the hyperparameters and what the source was for their value (e.g. paper, code or your guess). 

\subsection{Implementierung}
The programming language that is used in the replication task is Julia. Due to the restriction of time, we have mainly taken most of the code from the package Transformers.jl as a template for the implementation. Other packages which were also imported into the notebook include Flux.jl, Tullio.jl, NNlib.jl and so on. For the synthetic task, we use a version of copy task based on the experiment which was used by Kitaev et al. (2020). As mentioned above in 3.1, what we do to implement linear attention is to replace the attention function of Transformers.jl with our own code called LinearAttention, which has been translated from the original PyTorch code by (Katharopoulus et al., 2020) to Julia code. The original code requires in addition one more function called splitHeads to reshape the 3D tensor to 4D tensor, which we have also included in the script. Furthermore, as the authors used the activation function elu(x) + 1 in original paper instead of relu(x) as in the Transformers.jl, we also attempt to implement elu(x) + 1 (which was called nelu in our script) into the code to make sure that the performances of each model are not affected by different conditions and therefore they are comparable. Also we have trimmed the other unnecessary functions like \(apply\)\(\textunderscore\)\(mask\), … for the sake of simplification. Lastly, instead of using Kullback-Leibler divergence as loss function, we apply cross entropy to calculate the loss for the gradient descent as given in the original work.


................hier kommt noch code dazu

%Beschreiben sie, ob sie vorhandenen Code oder eigenen Code genutzt haben.
%Stellen sie Links zum Code bereit und beschreiben sie welche Programmiersprachen und Pakete genutzt wurden.
%Ihr Github oder Gitlab-Reposititory sollte öffentlich sein. 
%Das Reposititory sollte klar dokumentiert werden. 
%Describe whether you use the existing code or write your own code, with the link to the code and which programming languages/packages were used. Note that the github repo you link to should be public and have a clear documentation.

\subsection{Aufbau der Experimente}
The sequence for the copy task was first with start and end symbol, then embeded to become a 128x128 Matrix and goes through 4 layer of encoder as well as 4 layer of decoder. At the end, the loss can be computed for each iteration, so that we can monitor the improvement of loss over each iteration. Furthermore, we can also observe the execute time of each model after a certain amount of iteration. To do so, we use an Nvidia RTX … with … of memory.
%Erklären sie, wie sie ihre Experimente durchgeführt haben. Was für Ressourcen haben sie verwendet, z.B. GPU/CPU-Ressourcen.
%Verlinken sie ihren Code und Notebooks. 
%Explain how you ran your experiments, e.g. the CPU/GPU resources and provide the link to your code and notebooks. 

\subsection{Ressourcen für Berechnungen}
Beschreiben sie die Anforderungen für die Berechnungen für jedes ihrer Experimente, z.B. die Anzahl der CPU/GPU-Stunden oder die Voraussetzungen für den Hauptspeicher und GPU-Speicher. 
Geben sie für Zeit und Speicher eigene Abschätzungen an, bevor die Experimente gelaufen sind und vergleichen sie dies mit den tatsächlich verbrauchten Ressourcen.
Sie müssen vor den Experimenten einplanen, dass diese Informationen auch durch ihren Code gemessen und gespeichert werden.

% Provide information on computational requirements for each of your experiments. For example, the number of CPU/GPU hours and memory requirements.
% Mention both your estimation made before running the experiments (i.e. in the proposal) and the actual resources you used to reproducing the experiments. 
% \textbf{\textit{You'll need to think about this ahead of time, and write your code in a way that captures this information so you can later add it to this section.} }


\section{Ergebnisse}
Starten sie mit einem Überblick über die Ergebnisse.
Bestätigen ihre Ergebnisse die aufgeführten Behauptungen?
Dieser Abschnitt sollte hauptsächlich Fakten nennen und so präzise wie möglich geschrieben werden.
Die Bewertung und Diskussion kann im späteren Kapitel ``Diskussion'' folgen. 

% Start with a high-level overview of your results. Does your work support the claims you listed in section 2.1? Keep this section as factual and precise as possible, reserve your judgement and discussion points for the next ``Discussion'' section. 

Beschreiben sie dann detailliert jedes einzelne Ergebnis, das sie haben.
Zeigen sie wie es mit einer oder mehreren Behauptungen in Beziehung steht.
Erklären sie konkret was der Kern ihres Ergebnis ist.
Gruppieren sie die Ergebnisse in logische Abschnitte.
Beschreiben sie klar, wo sie über den Originalartikel hinausgegangen sind, wo sie zusätzliche Experimente durchgeführt haben und wie diese mit den ursprünglichen Behauptungen in Beziehung stehen.

% Go into each individual result you have, say how it relates to one of the claims, and explain what your result is. Logically group related results into sections. Clearly state if you have gone beyond the original paper to run additional experiments and how they relate to the original claims. 

Tipp 1: Drücken sie sich genau aus und verwenden sie eine klare und einfache Sprache, z.B. 
\begin{quote}
    ``we reproduced the accuracy to within 1\% of reported value, that upholds the paper's conclusion that it performs much better than baselines.'' oder

    ``We konnten die Klassifikationsrate bis auf 1\% des angegebenen Werts reproduzieren. Dies unterstützt die Schlussfolgerung der Artikels, dass der Ansatz leistungsfähiger als die Baselines ist.''
\end{quote}
Oft kann man nicht die exakt gleiche numerische Zahl als Ergebnis bekommen. Deshalb müssen sie das Ergebnis bewerten, um zu entscheiden, ob ihr Ergebnis die Behauptung der Originalartikels unterstützt.
% Getting exactly the same number is in most cases infeasible, so you'll need to use your judgement call to decide if your results support the original claim of the paper. 

Tipp 2: Nutzen sie Tabellen und Abbildungen, um ihre Ergebnisse darzustellen. 
% You may want to use tables and figures to demonstrate your results.

% The number of subsections for results should be the same as the number of hypotheses you are trying to verify.

\subsection{Ergebnis 1}

\subsection{Ergebnis 2}

\subsection{Zusätzliche Ergebnisse, die nicht im Originalartikel enthalten waren}
Beschreiben sie alle zusätzlichen Experimente, die über den Originalartikel hinausgehen.
Dies können Experimente zu weiteren Datenmengen sein oder sie probieren andere Methoden bzw. weitere Vereinfachungen des Modells aus oder passen die Hyperparameter an.
Beschreiben sie für jedes zusätzliche Experiment, was sie genau durchgeführt haben, was die Ergebnisse sind und diskutieren sie was diese Ergebnisse zeigen. 

% Describe any additional experiments beyond the original paper. This could include experimenting with additional datasets, exploring different methods, running more ablations, or tuning the hyperparameters. For each additional experiment, clearly describe which experiment you conducted, its result, and discussions (e.g. what is the indication of the result).

\section{Diskussion}
Beschreiben sie die weiterführenden Implikationen der experimentellen Ergebnisse.
War der Originalartikel replizierbar bzw. reproduzierbar.
Falls nicht, welche Faktoren haben dazu geführt, dass die Experimente nicht reproduziert werden konnten. 

% Describe larger implications of the experimental results, whether the original paper was reproducible, and if it wasn’t, what factors made it irreproducible. 

Bewerten sie, ob sie die Evidenz, die sie durch das Durchführen der Experimente erhalten haben, auch überzeugt, dass die Behauptungen des Originalartikels dadurch gestützt werden.
Diskutieren sie die Stärken und Schwächen ihres Ansatzes, vielleicht haben sie aus Zeitgründen nicht alle Experimente durchführen können, oder vielleicht haben zusätzliche Experimente durchgeführt, die den Originalartikel weiter stärken. 

% Give your judgement on if you feel the evidence you got from running the code supports the claims of the paper. Discuss the strengths and weaknesses of your approach -- perhaps you didn't have time to run all the experiments, or perhaps you did additional experiments that further strengthened the claims in the paper.


\subsection{Was war einfach?}
Beschreiben sie welche Teile der Replikation/Reproduktion sich leicht umsetzen ließen.
Lief der Code der Autoren problemlos? War es aufgrund der Beschreibung im Originalartikel nicht aufwändig die Methoden zu reimplementieren? 
Dieser Abschnitt soll den Lesenden zeigen, welche Teile des Originalartikels sich leicht für eigene Ansätze verwenden lässt. 

% Describe which parts of your reproduction study were easy. E.g. was it easy to run the author's code, or easy to re-implement their method based on the description in the paper. The goal of this section is to summarize to the reader which parts of the original paper they could easily apply to their problem. 

Tipp: Machen sie keine pauschalen Verallgemeinerungen. Was für sie leicht ist, muss für andere nicht leicht sein. Geben sie genügend Kontext und erklären sie warum manche Sachen leicht waren, z.B. der Code hatte eine umfangreiche Dokumentation der Schnittstellen und viele Beispiele aus der Dokumentation passten zu den Experimenten im Artikel. 

% Be careful not to give sweeping generalizations. Something that is easy for you might be difficult to others. Put what was easy in context and explain why it was easy (e.g. code had extensive API documentation and a lot of examples that matched experiments in papers). 

\subsection{Was war schwer?}
Beschreiben sie welche Teile ihrer Replikation/Reproduktion aufwändig oder schwierig waren oder viel mehr Zeit in Anspruch genommen haben, als sie erwarteten.
Vielleicht waren Daten nicht verfügbar, so dass sie einige Experimente nicht verifizieren konnten, oder der Code der Autoren funktionierte nicht und musste erst debugged werden.
Vielleicht dauerten auch einige Experimente zu lange und sie konnten sie deshalb nicht verifizieren.
Dieser Abschnitt soll den Lesenden zeigen, welche Teile des Originalartikels schwer wiederverwendbar sind, bzw. signifikante Zusatzarbeiten und Ressourcen erfordern. 

% Describe which parts of your reproduction study were difficult or took much more time than you expected. Perhaps the data was not available and you couldn't verify some experiments, or the author's code was broken and had to be debugged first. Or, perhaps some experiments just take too much time/resources to run and you couldn't verify them. The purpose of this section is to indicate to the reader which parts of the original paper are either difficult to re-use, or require a significant amount of work and resources to verify. 

Tipp: Setzen sie sorgfältig ihre Diskussion in den richtigen Kontext, z.B. sagen sie nicht `` die Mathematik war schwer verständlich'' sondern sagen sie `` die Mathematik erfordert fortgeschrittene Kenntnisse in Analysis für das Verständnis''.

% Be careful to put your discussion in context. For example, don't say ``the math was difficult to follow,'' say ``the math requires advanced knowledge of calculus to follow.'' 

\subsection{Empfehlungen für die Replizierbarkeit / Reproduzierbarkeit}
Geben sie Empfehlungen, wie die Autoren des Originalartikels oder andere Forschende in diesem Feld die Replizierbarkeit / Reproduzierbarkeit verbessern können.

% Describe a set of recommendations to the original authors or others who work in this area for improving reproducibility.

\section{Kommunikation mit den Autoren}
Our contact to the authors was unanswered. However, the issues section in the GitHub Repository contains questions that are also interesting in our case.

The user gaceladri made his own implementation of a Linear Transformer and shared a plot that showed, that the loss of a Linear Transformer is higher than the loss of a softmax-based Transformer (in this case a BERT model) when the gradient steps are lower than 10,000.  The user asked, if he has done something wrong regarding this discovery. Angelos Katharopoulos (username: angeloskath) answered, that this is possible, because the attention matrix of a Linear Transformer is low rank which leads to a harder learning process. The author further explains, that the whole point of Linear Transformers is an optimization of speed and memory. When these aspects are insignificant, using a softmax attention is probably better. 
https://github.com/idiap/fast-transformers/issues/84

The user Yogurt928 asked, why Einstein sums are used in the code, whereas the paper uses buzz signs. Katharopoulos responds: 
\begin{quote}
"The reason for using einsum instead of multiplication and summation is that it is faster since the large matrix does not need to ever be computed and kept in memory."
\end{quote}

At last, the user burcehan asked, why \(elu(x) + 1\) was used as the feature map.  He recognized, that the convergence of his model is very slow using this function.
Angelos Katharopoulos answers that the feature map needs to correspond to a non-negative similarity score. The question, whether other feature maps are better is an open research problem. In the tests for the paper, some feature maps achieved similar results, others not. All in all this depends on the analysed problem, but problems that require sparse attention patterns might be harder to learn using the \(elu(x) + 1\) feature map.

%Dokumentieren sie das Ausmaß (oder das Fehlen) der Kommunikation mit Autoren.
%Stellen sie sicher, dass der Bericht eine faire Beurteilung der Forschungsarbeiten ist. Versuchen sie deshalb mit den Autoren Kontakt aufzunehmen.
%Sie können ihnen konkrete Fragen stellen oder falls sie keine Fragen haben, den Bericht zusenden und um Feedback bitten.



% Document the extent of (or lack of) communication with the original authors. To make sure the reproducibility report is a fair assessment of the original research we recommend getting in touch with the original authors. You can ask authors specific questions, or if you don't have any questions you can send them the full report to get their feedback.



% \section{Lösungsansätze für das Problem}
% Kurze Zusammenfassung verwandter/konkurrierender Arbeiten, die das Problem auf ähnliche Weise lösen (zwei Artikel oder mehr)
% Erste Gruppe von Artikeln 
% Zweite Gruppe von Artikeln
% Kurze Zusammenfassung von Arbeiten, Methoden oder Techniken auf denen der replizierte Artikel aufbaut (zwei Artikel oder mehr)
% Erste Gruppe von Artikeln 
% Zweite Gruppe von Artikeln 
% Kurze Beschreibung des/der Ansatzes/Ansätze, die für die Replikation ausgewählt wurden.
% Offene Details, die im replizierten Artikel nicht oder unvollständig beschrieben wurden und die nicht zitierten Artikeln geklärt werden.
% Welche Details können durch die Reproduktion geklärt und ergänzt werden? Erklären Sie diese Details.
% Welche Prinzipien, Ideen, Grundlagen oder Annahmen stehen hinter dem replizierten Ansatz?



% \section{Empirische Evaluation und Replikation}
% Beschreibung der Implementierung 
% Beschreibung von einfachen Tests, die die Korrektheit der Implementierung belegen
% Beschreibung des Speicherverbrauchs und der Laufzeit-Performance der Implementierung
% Beschreibung der Ausgangsdaten
% Beschreibung der Vorverarbeitung der Daten
% Beschreibung der Replikation des/der Experiment/e
% Beschreibung von Schwierigkeiten und Problemen



% \section{Zusammenfassung}
% Ist der Ansatz gut genug, um das Problem als gelöst zu betrachten?
% Welche Schwierigkeiten des Ansatzes deckte die Replikation auf?
% Welche Forschungenrichtungen halten Sie für künftige Untersuchen für potentiell wichtig?

% \section{Entwicklung und Julia-Code}
% Implementierung Datenvorverarbeitung 
% Implementierung Modell
% Implementierung von Tests, Ausgaben, Grafiken, die Arbeitsweise und Korrektheit belegen
% Implementierung zur Auswertung offener Details im replizierten Artikel
% Implementierung des replizierten Experiments, Evaluation
% Implementierung Evaluationsauswertung



\end{document}
