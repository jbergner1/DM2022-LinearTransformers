{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "begin\n",
    "\tusing BSON\n",
    "\tusing CUDA\n",
    "\tusing DrWatson: struct2dict\n",
    "\tusing Flux\n",
    "\tusing Flux: @functor, chunk\n",
    "\tusing Flux.Losses: logitbinarycrossentropy\n",
    "\tusing Flux.Data: DataLoader\n",
    "\tusing Images\n",
    "\tusing Logging: with_logger\n",
    "\tusing MLDatasets\n",
    "\tusing Parameters: @with_kw\n",
    "\tusing ProgressMeter: Progress, next!\n",
    "\tusing TensorBoardLogger: TBLogger, tb_overwrite\n",
    "\tusing Random\n",
    "\tusing Plots\n",
    "\tusing Statistics\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST images and return loader\n",
    "function get_data(batch_size)\n",
    "\t# muss nur beim ersten Laufen und kann dann auskommentiert werden\n",
    "\tMLDatasets.MNIST.download(i_accept_the_terms_of_use=true)\n",
    "\t\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "    xtrain = reshape(xtrain, 28^2, :)\n",
    "    DataLoader((xtrain, ytrain), batchsize=batch_size, shuffle=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "\tstruct Encoder\n",
    "\t    linear\n",
    "\t    μ\n",
    "\t    logσ\n",
    "\tend\n",
    "\t@functor Encoder\n",
    "\t\n",
    "\tEncoder(input_dim::Int, latent_dim::Int, hidden_dim::Int) = Encoder(\n",
    "    Dense(input_dim, hidden_dim, tanh),   # linear\n",
    "    Dense(hidden_dim, latent_dim),        # μ\n",
    "    Dense(hidden_dim, latent_dim),        # logσ\n",
    "\t)\n",
    "\n",
    "\tfunction (encoder::Encoder)(x)\n",
    "\t\th = encoder.linear(x)\n",
    "\t\tencoder.μ(h), encoder.logσ(h)\n",
    "\tend\n",
    "\tDecoder(input_dim::Int, latent_dim::Int, hidden_dim::Int) = Chain(\n",
    "\t\tDense(latent_dim, hidden_dim, tanh),\n",
    "\t\tDense(hidden_dim, input_dim)\n",
    "\t)\n",
    "\n",
    "\tfunction reconstuct(encoder, decoder, x, device)\n",
    "\t\tμ, logσ = encoder(x)\n",
    "\t\tz = μ + device(randn(Float32, size(logσ))) .* exp.(logσ)\n",
    "\t\tμ, logσ, decoder(z)\n",
    "\tend\n",
    "\n",
    "\tfunction model_loss(encoder, decoder, λ, x, device)\n",
    "\t\tμ, logσ, decoder_z = reconstuct(encoder, decoder, x, device)\n",
    "\t\tlen = size(x)[end]\n",
    "    \t# KL-divergence\n",
    "    \tkl_q_p = 0.5f0 * sum(@. (exp(2f0 * logσ) + μ^2 -1f0 - 2f0 * logσ)) / len\n",
    "\t\t\n",
    "    \tlogp_x_z = -logitbinarycrossentropy(decoder_z, x, agg=sum) / len\n",
    "    \t# regularization\n",
    "    \treg = λ * sum(x->sum(x.^2), Flux.params(decoder))\n",
    "\t\t\n",
    "    \t-logp_x_z + kl_q_p + reg\n",
    "\tend\n",
    "\n",
    "\tfunction convert_to_image(x, y_size)\n",
    "    \tGray.(permutedims(vcat(reshape.(chunk(x |> cpu, y_size), 28, :)...), (2, 1)))\n",
    "\tend\n",
    "\t\n",
    "\t# arguments for the `train` function \n",
    "\t@with_kw mutable struct Args\n",
    "    \tη = 1e-3                # learning rate\n",
    "    \tλ = 0.01f0              # regularization paramater\n",
    "    \tbatch_size = 128        # batch size\n",
    "    \tsample_size = 10        # sampling size for output    \n",
    "    \tepochs = 20             # number of epochs\n",
    "    \tseed = 0                # random seed\n",
    "    \tcuda = true             # use GPU\n",
    "    \tinput_dim = 28^2        # image size\n",
    "    \tlatent_dim = 2          # latent dimension\n",
    "    \thidden_dim = 500        # hidden dimension\n",
    "    \tverbose_freq = 10       # logging for every verbose_freq iterations\n",
    "    \ttblogger = false        # log training with tensorboard\n",
    "    \tsave_path = \"output\"    # results path\n",
    "\tend\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(; kws...)\n",
    "    # load hyperparamters\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "\n",
    "    # GPU config\n",
    "    if args.cuda && CUDA.has_cuda()\n",
    "        device = gpu\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "\n",
    "    # load MNIST images\n",
    "    loader = get_data(args.batch_size)\n",
    "    \n",
    "    # initialize encoder and decoder\n",
    "    encoder = Encoder(args.input_dim, args.latent_dim, args.hidden_dim) |> device\n",
    "    decoder = Decoder(args.input_dim, args.latent_dim, args.hidden_dim) |> device\n",
    "\n",
    "    # ADAM optimizer\n",
    "    opt = ADAM(args.η)\n",
    "    \n",
    "    # parameters\n",
    "    ps = Flux.params(encoder.linear, encoder.μ, encoder.logσ, decoder)\n",
    "\n",
    "    !ispath(args.save_path) && mkpath(args.save_path)\n",
    "\n",
    "    # logging by TensorBoard.jl\n",
    "    if args.tblogger\n",
    "        tblogger = TBLogger(args.save_path, tb_overwrite)\n",
    "    end\n",
    "\n",
    "    # fixed input\n",
    "    original, _ = first(get_data(args.sample_size^2))\n",
    "    original = original |> device\n",
    "    image = convert_to_image(original, args.sample_size)\n",
    "    image_path = joinpath(args.save_path, \"original.png\")\n",
    "    save(image_path, image)\n",
    "\n",
    "    # training\n",
    "    train_steps = 0\n",
    "\tepochenLosses = [[]]\n",
    "    @info \"Start Training, total $(args.epochs) epochs\"\n",
    "    for epoch = 1:args.epochs\n",
    "        @info \"Epoch $(epoch)\"\n",
    "        progress = Progress(length(loader))\n",
    "\t\tlosses = []\n",
    "\t\t\n",
    "        for (x, _) in loader \n",
    "            loss, back = Flux.pullback(ps) do\n",
    "                model_loss(encoder, decoder, args.λ, x |> device, device)\n",
    "            end\n",
    "\t\t\tpush!(losses,loss)\n",
    "            grad = back(1f0)\n",
    "            Flux.Optimise.update!(opt, ps, grad)\n",
    "            # progress meter\n",
    "            next!(progress; showvalues=[(:loss, loss)]) \n",
    "\n",
    "            # logging with TensorBoard\n",
    "            if args.tblogger && train_steps % args.verbose_freq == 0\n",
    "                with_logger(tblogger) do\n",
    "                    @info \"train\" loss=loss\n",
    "                end\n",
    "            end\n",
    "\t\t\t\n",
    "            train_steps += 1\n",
    "        end\n",
    "        # save image\n",
    "        _, _, rec_original = reconstuct(encoder, decoder, original, device)\n",
    "        rec_original = sigmoid.(rec_original)\n",
    "        image = convert_to_image(rec_original, args.sample_size)\n",
    "        image_path = joinpath(args.save_path, \"epoch_$(epoch).png\")\n",
    "        save(image_path, image)\n",
    "        @info \"Image saved: $(image_path)\"\n",
    "\t\tpush!(epochenLosses,losses)\n",
    "    end\n",
    "\n",
    "    # save model\n",
    "    model_path = joinpath(args.save_path, \"model.bson\") \n",
    "    let encoder = cpu(encoder), decoder = cpu(decoder), args=struct2dict(args)\n",
    "        BSON.@save model_path encoder decoder args\n",
    "        @info \"Model saved: $(model_path)\"\n",
    "    end\n",
    "\treturn epochenLosses\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochenLosses = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(epochenLosses[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_data = BSON.load(\"output/model.bson\", @__MODULE__) #encoder decoder args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder=loaded_data[:encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder=loaded_data[:decoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args=loaded_data[:args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_result()\n",
    "    #BSON.@load \"output/model.bson\" encoder decoder args\n",
    "    loaded_data = BSON.load(\"output/model.bson\", @__MODULE__) #encoder decoder args\n",
    "\tencoder=loaded_data[:encoder]\n",
    "\tdecoder=loaded_data[:decoder]\n",
    "\targs=loaded_data[:args]\n",
    "    #args = Args(; args...)\n",
    "    #device = args.cuda && CUDA.has_cuda() ? gpu : cpu\n",
    "    device =  cpu\n",
    "    encoder, decoder = encoder |> device, decoder |> device\n",
    "    # load MNIST images\n",
    "    loader = get_data(args[:batch_size])\n",
    "\n",
    "    # clustering in the latent space\n",
    "    # visualize first two dims\n",
    "    plt = scatter(palette=:rainbow)\n",
    "    for (i, (x, y)) in enumerate(loader)\n",
    "        i < 20 || break\n",
    "        μ, logσ = encoder(x |> device)\n",
    "        scatter!(μ[1, :], μ[2, :], \n",
    "            markerstrokewidth=0, markeralpha=0.8,\n",
    "            aspect_ratio=1,\n",
    "            markercolor=y, label=\"\")\n",
    "    end\n",
    "    #savefig(plt, \"output/clustering.png\")\n",
    "\n",
    "    z = range(-2.0, stop=2.0, length=11)\n",
    "    len = Base.length(z)\n",
    "    z1 = repeat(z, len)\n",
    "    z2 = sort(z1)\n",
    "    x = zeros(Float32, args[:latent_dim], len^2) |> device\n",
    "    x[1, :] = z1\n",
    "    x[2, :] = z2\n",
    "    samples = decoder(x)\n",
    "    samples = sigmoid.(samples)\n",
    "    image = convert_to_image(samples, len)\n",
    "    #save(\"output/manifold.png\", image)\n",
    "\t(plt, image)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, image = plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rekonstruktion des Bereichs -2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "    struct Wow\n",
    "    filename\n",
    "    end\n",
    "    \n",
    "    function Base.show(io::IO, ::MIME\"image/png\", w::Wow)\n",
    "    write(io, read(w.filename))\n",
    "    end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Wow(\"output/epoch_1.png\"),Wow(\"output/original.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Wow(\"output/epoch_5.png\"),Wow(\"output/original.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Wow(\"output/epoch_10.png\"),Wow(\"output/original.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Wow(\"output/epoch_20.png\"),Wow(\"output/original.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Aufgaben\n",
    "#Speichern sie den Trainingsfehler in jeder der 20 Epochen in einem Feld und stellen sie ihn als Liniendigramm Epoche x Fehler dar.\n",
    "#Probieren sie vier verschiedene Werte für die Dimension des Latenten Raumes: 2, 5, 10, 100 und stellen sie die vier Kurven der Trainingsfehler über die Epochen in einem Liniendigramm Epoche x Fehler dar. Die Darstellung des Latenten Raumes müssen sie bei Dimensionen ungleich 2 abschalten, ebenso die Darstellung des Bereichs -2:2 x -2:2.\n",
    "#Wählen 11 Punkte im gleichen Abstand auf einer Diagonale von (-2,...,-2) bis (2,...,2), rekonstruieren sie die Bilder zu den gewählten Punkten und zeigen sie die Bilder an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufgabe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(vcat(epochenLosses[2:21]...), label=\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochenLosses_5 = train(latent_dim = 5, save_path=\"output_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochenLosses_10 = train(latent_dim = 10, save_path=\"output_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochenLosses_100 = train(latent_dim = 100, save_path=\"output_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "\tplot(vcat(epochenLosses[2:21]...), label=\"Losses, dim = 2\")\n",
    "\tplot!(vcat(epochenLosses[2:21]...), label=\"Losses, dim = 5\")\n",
    "\tplot!(vcat(epochenLosses[2:21]...), label=\"Losses, dim = 10\")\n",
    "\tplot!(vcat(epochenLosses[2:21]...), label=\"Losses, dim = 100\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = BSON.load(\"output/model.bson\", @__MODULE__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_diagonal(path=\"output\")\n",
    "\t#BSON.@load \"output/model.bson\" encoder decoder args\n",
    "\tloaded_data = BSON.load(\"output/model.bson\", @__MODULE__) #encoder decoder args\n",
    "\tencoder=loaded_data[:encoder]\n",
    "\tdecoder=loaded_data[:decoder]\n",
    "\targs=loaded_data[:args]\n",
    "\t#args = Args(; args...)\n",
    "\t#device = args.cuda && CUDA.has_cuda() ? gpu : cpu\n",
    "\tdevice = cpu\n",
    "\tencoder, decoder = encoder |> device, decoder |> device\n",
    "\t\n",
    "\tz = range(-2.0, stop=2.0, length=11)\n",
    "\tlen = Base.length(z)\n",
    "\tx = repeat(z, outer = [1, args[:latent_dim]])' |> device\n",
    "\tsamples = decoder(x)\n",
    "\tsamples = sigmoid.(samples)\n",
    "\timage = convert_to_image(samples, len)\n",
    "\timage\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diagonal(\"output\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e70d5a55149c324a78f2e3dc42d4d145635e9b55bf346af69a9482614d304c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
